{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a73db4",
   "metadata": {},
   "source": [
    "# Kinematic Data Augmention\n",
    "\n",
    "This notebook demonstrates a data augmentation process for kinematic data, including the estimation of additional joint positions, angles, and distances, using geometric methods for both relative and absolute values, with the assumption that the performer is in an upright position.\n",
    "\n",
    "### Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115493ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c101b4c",
   "metadata": {},
   "source": [
    "## Relative and Absolute Values\n",
    "\n",
    "Converting kinematic data to absolute values can be useful for measuring the movement of a performer in physical space, while using relative data is better for capturing movement characteristics independent of physical space, such as the relative positions of the limbs. For our research, we will keep both absolute and relative kinematic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 360, 640\n",
    "kd_rel = pd.read_csv('./data/processed/contemporary_001.csv')\n",
    "kd_abs = kd_rel.copy()\n",
    "\n",
    "kd_abs.loc[:, kd_abs.columns.str.endswith('_x')] *= w\n",
    "kd_abs.loc[:, kd_abs.columns.str.endswith('_y')] *= h\n",
    "kd_abs.loc[:, kd_abs.columns.str.endswith('_z')] = h - kd_abs.loc[:, kd_abs.columns.str.endswith('_z')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20fb92",
   "metadata": {},
   "source": [
    "## Augmenting Joint Positions\n",
    "\n",
    "MediaPipe's current implementation involves using 32 landmarks to identify joints (as shown in a reference picture). In order to gain a more comprehensive understanding of body alignment and posture during performances, we have estimated additional joint positions, which can be helpful in achieving this goal.\n",
    "\n",
    "![Image](https://mediapipe.dev/images/mobile/pose_tracking_full_body_landmarks.png)\n",
    "\n",
    "### Forehead Joint\n",
    "\n",
    "This computation estimates the position of the forehead joint using the average position of the outer corners of both eyes in both relative and absolute kinematic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_rel.loc[:, 'forehead_x'] = (kd_rel['left_eye_outer_x'] + kd_rel['right_eye_outer_x']) / 2\n",
    "kd_rel.loc[:, 'forehead_y'] = (kd_rel['left_eye_outer_y'] + kd_rel['right_eye_outer_y']) / 2\n",
    "kd_rel.loc[:, 'forehead_z'] = (kd_rel['left_eye_outer_z'] + kd_rel['right_eye_outer_z']) / 2\n",
    "\n",
    "kd_abs.loc[:, 'forehead_x'] = (kd_abs['left_eye_outer_x'] + kd_abs['right_eye_outer_x']) / 2\n",
    "kd_abs.loc[:, 'forehead_y'] = (kd_abs['left_eye_outer_y'] + kd_abs['right_eye_outer_y']) / 2\n",
    "kd_abs.loc[:, 'forehead_z'] = (kd_abs['left_eye_outer_z'] + kd_abs['right_eye_outer_z']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0184f57",
   "metadata": {},
   "source": [
    "### Torso Joint\n",
    "\n",
    "This computation estimates the location of the torso joint by averaging the positions of the left and right shoulders and left and right hips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_rel.loc[:, 'torso_x'] = (kd_rel['left_shoulder_x'] + kd_rel['right_shoulder_x'] + kd_rel['left_hip_x'] + kd_rel['right_hip_x']) / 4\n",
    "kd_rel.loc[:, 'torso_y'] = (kd_rel['left_shoulder_y'] + kd_rel['right_shoulder_y'] + kd_rel['left_hip_y'] + kd_rel['right_hip_y']) / 4\n",
    "kd_rel.loc[:, 'torso_z'] = (kd_rel['left_shoulder_z'] + kd_rel['right_shoulder_z'] + kd_rel['left_hip_z'] + kd_rel['right_hip_z']) / 4\n",
    "\n",
    "kd_abs.loc[:, 'torso_x'] = (kd_abs['left_shoulder_x'] + kd_abs['right_shoulder_x'] + kd_abs['left_hip_x'] + kd_abs['right_hip_x']) / 4\n",
    "kd_abs.loc[:, 'torso_y'] = (kd_abs['left_shoulder_y'] + kd_abs['right_shoulder_y'] + kd_abs['left_hip_y'] + kd_abs['right_hip_y']) / 4\n",
    "kd_abs.loc[:, 'torso_z'] = (kd_abs['left_shoulder_z'] + kd_abs['right_shoulder_z'] + kd_abs['left_hip_z'] + kd_abs['right_hip_z']) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc6ab8",
   "metadata": {},
   "source": [
    "## Augmenting Joint Angles and Magnitude\n",
    "Augmenting joint angles and distances using dot product and Euclidean distance can be used to extract body alignment and posture during a performance. The joint pairs defined represent connections between limbs in the human body.\n",
    "\n",
    "### Defining Connected Joints\n",
    "The joint pairs defined represent connections between limbs in the human body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_pairs = [('right_shoulder', 'right_elbow'), ('right_elbow', 'right_wrist'), ('right_hip', 'right_knee'), ('right_knee', 'right_ankle'), ('right_ankle', 'right_foot_index'), ('left_shoulder', 'left_elbow'), ('left_elbow', 'left_wrist'), ('left_hip', 'left_knee'), ('left_knee', 'left_ankle'), ('left_ankle', 'left_foot_index'), ('forehead', 'torso')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d1796",
   "metadata": {},
   "source": [
    "### Computing Angles and Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "for joint in joint_pairs:\n",
    "    angles = []\n",
    "    for i in range(kd_rel.shape[0]):\n",
    "        joint1 = np.array([kd_rel[f\"{joint[0]}_x\"].iloc[i], kd_rel[f\"{joint[0]}_y\"].iloc[i], kd_rel[f\"{joint[0]}_z\"].iloc[i]])\n",
    "        joint2 = np.array([kd_rel[f\"{joint[1]}_x\"].iloc[i], kd_rel[f\"{joint[1]}_y\"].iloc[i], kd_rel[f\"{joint[1]}_z\"].iloc[i]])     \n",
    "        dot_product = np.dot(joint1, joint2)\n",
    "        mag1 = np.linalg.norm(joint1)\n",
    "        mag2 = np.linalg.norm(joint2)\n",
    "        dist = np.linalg.norm(joint1 - joint2)\n",
    "        angle = np.degrees(np.arccos(dot_product / (mag1 * mag2)))\n",
    "        angles.append(angle)\n",
    "    kd_rel[f\"a_{joint[0]}_{joint[1]}\"] = angles\n",
    "    kd_rel[f\"d_{joint[0]}_{joint[1]}\"] = dist\n",
    "    \n",
    "for joint in joint_pairs:\n",
    "    angles = []\n",
    "    for i in range(kd_abs.shape[0]):\n",
    "        joint1 = np.array([kd_abs[f\"{joint[0]}_x\"].iloc[i], kd_abs[f\"{joint[0]}_y\"].iloc[i], kd_abs[f\"{joint[0]}_z\"].iloc[i]])\n",
    "        joint2 = np.array([kd_abs[f\"{joint[1]}_x\"].iloc[i], kd_abs[f\"{joint[1]}_y\"].iloc[i], kd_abs[f\"{joint[1]}_z\"].iloc[i]])    \n",
    "        dot_product = np.dot(joint1, joint2)\n",
    "        mag1 = np.linalg.norm(joint1)\n",
    "        mag2 = np.linalg.norm(joint2)\n",
    "        angle = np.degrees(np.arccos(dot_product / (mag1 * mag2)))\n",
    "        angles.append(angle)\n",
    "    kd_abs[f\"a_{joint[0]}_{joint[1]}\"] = angles\n",
    "    kd_abs[f\"d_{joint[0]}_{joint[1]}\"] = dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c67df",
   "metadata": {},
   "source": [
    "### Save Processed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_abs.to_csv('./data/processed/contemporary_001_abs.csv', index=False)\n",
    "kd_rel.to_csv('./data/processed/contemporary_001_rel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7420b",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "For more details about the data augmentation processing, please refer to the code in [/src/data/augmentation.py](https://github.com/kayesokua/gestures/blob/main/src/data/augmentation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06351f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.augmentation import batch_data_augmentation\n",
    "\n",
    "batch_data_augmentation(\"./data/processed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "300b886a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* The data augmentation process enriches kinematic data by adding new joint positions, angles, and distances which may extract further insights on gestures.\n",
    "* The analysis can be performed on both absolute and relative values for the available landmarks, which might extract insight on spatial patterns.\n",
    "    * Augmented Kinematic data using absolute values: `data/processed/{category_i}_abs.csv`\n",
    "    * Augmented Kinematic data using absolute values: `data/processed/{category_i}_rel.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
