# Computational Decoding of Dance Gestures

Dance is a long-standing form of human expression, used to convey emotions, tell stories, and entertain audiences. However, providing informative feedback on dance performances can be challenging due to the subjective nature of traditional descriptions. These descriptions are reliant upon the observer's personal interpretation of the dance movements, which can be heavily influenced by various factors such as their background and the context of the performance. This subjectivity can hinder the provision of comprehensive and impartial feedback, thereby impeding the dancers' growth in developing their artistic style and advancing the art form.

An essential element of dance is gestures, which are defined as movements made by the dancer to express a particular idea or emotion. These movements can range from subtle to overt and include various parts of the body, such as the hands, arms, head, and body. The two primary categories of gestures in dance are behavioral and expressive gestures. In this project, I aim to explore computational methods that can be used to describe a dance performance with a focus on gestures.

## Background Concepts

Below are some quick-reference resources, including Wikipedia articles and abstracts, that can help you gain a better understanding of the project.

* [Viewpoints](https://en.wikipedia.org/wiki/Viewpoints) is a technique of dance composition that acts as a medium for thinking about and acting upon movement, gesture and creative space.
* [Pose estimation](https://en.wikipedia.org/wiki/Pose_(computer_vision)) refers to the process of determining the spatial arrangement of key points or body parts (such as human joints) within an image or video, allowing for the extraction of valuable information about an object's position, orientation, and movement.
* [Gesture Recognition](https://en.wikipedia.org/wiki/Gesture_recognition) is a topic in computer science and language technology with the goal of interpreting human gestures via mathematical algorithms.
* [Kinematics](https://en.wikipedia.org/wiki/Kinematics) is the study of motion without considering the forces that cause it. The principles of kinematics are going to be used to detect and understand gestures in dance performance.
* [Spatio-temporal Gabors](http://europepmc.org/article/MED/3973762) are mathematical functions used to analyze and represent complex patterns in space and time, often applied in computer vision and image processing to capture the motion and texture information in video sequences. In this project, the motion energy features are extracted using this framework.
* [Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) is linear dimensionality reduction technique used in exploratory data analysis.
* [Hidden Markov Model](https://en.wikipedia.org/wiki/Hidden_Markov_model) is a statistical model that describes the sequence of observations generated by an underlying process with unknown states, and useful for undestanding transitions and gesture sequence.

## Notebooks

The notebooks are organized in a chronological sequence and it is recommended to follow this order for better understanding.

`1_introduction.ipynb`.: This notebook provides an overview of the data collection process and the approach to preprocessing the kinematic data for the downloaded dance video dataset.

`2_data_augmentation.ipynb`: This notebook demonstrates a data augmentation process for kinematic data, including the estimation of additional joint positions, angles, and distances, using geometric methods for both relative and absolute values, with the assumption that the performer is in an upright position.

`3_performance_analysis.ipynb`: This notebook analyzes and visualizes dance performances using joint trajectories, motion energy mapping, and PCA for variety examination. The descriptive statistics offer insights into gesture extraction.

`4_behavioral_gestures.ipynb`: This notebook presents pose and gesture methodologies, employing analytic and geometric methods to extract gestures from kinematic data. Due to the lack of existing models for dance gesture extraction, basic behavioral gestures like standing, sitting, and bending knees serve as a starting point, though fine-tuning may be necessary for overlaps and varying contexts.

`5_expressive_gestures.ipynb`: This notebook demonstrates how to derive expressions from extracted behavioral gestures, incorporating music, timing, and speed into the context. It also emphasizes the importance of understanding gesture transitions and sequences using Hidden Markov Models.

`6_comparative_analysis.ipynb`: This notebook summarizes the techniques used to analyze a dance, comparing it with two other similar videos and two videos from another genre.

`7_conclusion.ipynb`: This notebook presents the findings of the EDA and discusses the limitations of the proposed system for describing dance performances for the purpose of providing objective feedback for training.

## File Structure

This project follows the suggested folder structure of [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/).

## Resources

Please see [Resources](https://github.com/kayesokua/gestures/tree/main/references) for a comprehensive list of the resources used in this project.
