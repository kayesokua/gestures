{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook provides an overview of the data collection process and the approach to preprocessing the kinematic data for the downloaded dance video dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection using Youtube Data API and Pytube\n",
    "\n",
    "The video data used for exploratory data analysis was downloaded using the [Youtube Data API](https://developers.google.com/youtube/v3/docs/search/list) and [Pytube](https://pytube.io/en/latest/), which ensured that only authorized videos were collected for analysis. To increase the likelihood of finding relevant and clean videos that focused on individual dancers rather than groups, the code function used a keyword search that included the genre name and terms such as \"solo choreography\", \"solo practice\", or \"dance cover\". The expected video format is `mp4`, `width:360`, `height:640`, `max_length:120`, `min_views:100`.\n",
    "\n",
    "For more details about the data collection process, please refer to the code in [/src/data/collection.py](https://github.com/kayesokua/gestures/blob/main/src/data/collection.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.collection import extract_video_from_youtube\n",
    "\n",
    "extract_video_from_youtube(query='contemporary', max_count=5)\n",
    "extract_video_from_youtube(query='ballet', max_count=5)\n",
    "extract_video_from_youtube(query='folk', max_count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation using MediaPipe\n",
    "\n",
    "After downloading the video data, the kinematic data will be extracted using [MediaPipe Pose Solution](https://github.com/google/mediapipe/blob/master/docs/solutions/pose.md). The chosen output format is `csv` with relative values by default. In this file, we obtain `x`,`y`,`z` coordinates and obtain the `fps` using [OpenCV](https://docs.opencv.org/4.x/). We use `NaN` to frames where a pose cannot be detected. \n",
    "\n",
    "The code snippet below gathers all videos in `mp4` format and extracts landmarks and screenshots. For more details about the data annotation process, please refer to the code in [/src/data/annotation.py](https://github.com/kayesokua/gestures/blob/main/src/data/annotation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.data.annotation import extract_landmarks_from_videos\n",
    "\n",
    "video_path = 'data/external/test'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    extract_landmarks_from_videos(video_path)\n",
    "else:\n",
    "    print(\"Path does not exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Poses and Outlier Detection\n",
    "\n",
    "Since we are handling dance videos with different cinematography style, using linear interpolation or median might not be appropriate for handling missing kinematic data. Therefore, the proposed solution is to detect outliers instead by generating binary label using [Isolation Forest algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).  `1` indicates normal data and `-1` indicates the outlier.\n",
    "\n",
    "For more details about the data annotation process, please refer to the code in [/src/data/processing.py](https://github.com/kayesokua/gestures/blob/main/src/data/processing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.processing import process_landmarks_using_isolation_forest\n",
    "process_landmarks_using_isolation_forest(\"data/interim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook provided an overview of the data we have for exploration\n",
    "\n",
    "1. Videos (MP4) with category as filename: `data/external/{category_i}.mp4`\n",
    "2. Kinematic data extracted using MediaPipe(CSV): `data/interim/{category_i}/landmarks_rel.csv`\n",
    "3. Kinematic data with outliers information(CSV): `data/processed/{category_i}.csv`\n",
    "4. Frame screenshots (PNG) saved in chronological order: `data/interim/{video_filename}/*.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
